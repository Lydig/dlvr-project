{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10557597",
   "metadata": {},
   "source": [
    "# Experiment 07: Attention U-Net with Cyclical Learning Rate (CLR)\n",
    "\n",
    "This notebook addresses the training instability observed in previous experiments. We will use a Cyclical Learning Rate (CLR) schedule instead of a constant learning rate. The goal is to help the optimizer escape poor local minima and find a more robust solution.\n",
    "\n",
    "### **Methodology**\n",
    "\n",
    "This is a two-part experiment:\n",
    "1.  **LR Range Test**: We first run a short training process where we linearly increase the learning rate from a very small to a large value. We plot the loss vs. the learning rate to identify the optimal range where the loss decreases most rapidly.\n",
    "2.  **Full Training**: We use the identified optimal range to train our full model for 50 epochs using a CLR scheduler.\n",
    "\n",
    "### **Model Configuration**\n",
    "\n",
    "*   **Objective**: Stabilize training and improve performance using a CLR schedule.\n",
    "*   **Model Architecture**: Attention U-Net.\n",
    "*   **Dataset**: D2_TCPW, eligible patients.\n",
    "*   **Preprocessing**: RAovSeg custom preprocessing.\n",
    "*   **Loss Function**: Focal Tversky Loss.\n",
    "*   **Optimizer**: Adam.\n",
    "*   **Learning Rate**: **Cyclical, varying between a min and max bound.**\n",
    "*   **Epochs**: 50.\n",
    "*   **Batch Size**: 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d18f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Data for LR Range Test ---\n",
      "Loading manifest from ../data/d2_manifest_t2fs_ovary_eligible.csv and creating slice map...\n",
      "Slice map created. Found 278 slices containing the ovary.\n",
      "\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR Range Test:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# --- Imports and Setup ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.data_loader import UterusDatasetWithPreprocessing \n",
    "from src.models import AttentionUNet\n",
    "from src.losses import FocalTverskyLoss\n",
    "\n",
    "# --- Configuration for LR Range Test ---\n",
    "manifest_path = '../data/d2_manifest_t2fs_ovary_eligible.csv'\n",
    "image_size = 256\n",
    "batch_size = 16\n",
    "start_lr = 1e-7\n",
    "end_lr = 1e-1\n",
    "num_steps = 20 # Number of steps to increase the LR\n",
    "\n",
    "# --- Data Loading ---\n",
    "print(\"--- Loading Data for LR Range Test ---\")\n",
    "# Only need the training data for this test\n",
    "train_full_dataset = UterusDatasetWithPreprocessing(manifest_path=manifest_path, image_size=image_size, augment=True)\n",
    "patient_ids = train_full_dataset.manifest['patient_id'].unique()\n",
    "split_idx = int(len(patient_ids) * 0.8)\n",
    "train_ids = patient_ids[:split_idx]\n",
    "train_indices = [i for i, sm in enumerate(train_full_dataset.slice_map) if train_full_dataset.manifest.loc[sm['patient_index'], 'patient_id'] in train_ids]\n",
    "train_dataset = Subset(train_full_dataset, train_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# --- LR Range Test Logic ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "model = AttentionUNet(n_channels=1, n_classes=1).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=start_lr) # Start with a very small LR\n",
    "criterion = FocalTverskyLoss(alpha=0.7, beta=0.3, gamma=4/3)\n",
    "\n",
    "# Linearly increase LR from start_lr to end_lr over num_steps\n",
    "lr_lambda = lambda step: (end_lr / start_lr) ** (step / num_steps)\n",
    "scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "learning_rates = []\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "iterator = iter(train_loader)\n",
    "for step in tqdm(range(num_steps), desc=\"LR Range Test\"):\n",
    "    try:\n",
    "        images, masks = next(iterator)\n",
    "    except StopIteration:\n",
    "        iterator = iter(train_loader)\n",
    "        images, masks = next(iterator)\n",
    "\n",
    "    images, masks = images.to(device), masks.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, masks)\n",
    "    \n",
    "    # Break if loss explodes\n",
    "    if torch.isnan(loss) or loss > 4 * min(losses, default=1.0):\n",
    "        print(\"Loss exploded, stopping test.\")\n",
    "        break\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    learning_rates.append(scheduler.get_last_lr()[0])\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "# --- Plot the Results ---\n",
    "print(\"Plotting LR Range Test Results...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(learning_rates, losses)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Learning Rate (log scale)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Rate Range Test\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvr-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
