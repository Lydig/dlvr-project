{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aafbed87",
   "metadata": {},
   "source": [
    "# Notebook 22 – Unified Model Evaluation (original vs masked validation)\n",
    "\n",
    "In this notebook we:\n",
    "- Load all trained ovary segmentation models (baseline, attention, RAovSeg, Focal Tversky, TL-5, masked model).\n",
    "- Evaluate each model on the **same** validation set (positive ovary slices only).\n",
    "- Evaluate each model again on **ovary-side masked** validation images.\n",
    "- Summarise results in a table: Val Dice (orig), Val Dice (masked), and ΔDice = masked − orig.\n",
    "\n",
    "This is a sanity check and will give us the final numbers for Table 1 in the report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07f0f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\lytten\\programming\\dlvr-project\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Make project root importable (assuming this notebook lives in notebooks/)\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "\n",
    "from src.data_loader import UterusDataset, UterusDatasetWithPreprocessing\n",
    "from src.models import UNet, AttentionUNet, DoubleConv, AttentionGate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a55f1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "def dice_score(preds, targets, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Compute Dice score between binary predictions and binary targets.\n",
    "    preds, targets: (B, 1, H, W) tensors with {0,1} values.\n",
    "    \"\"\"\n",
    "    preds_flat = preds.view(-1)\n",
    "    targets_flat = targets.view(-1)\n",
    "    intersection = (preds_flat * targets_flat).sum()\n",
    "    return (2.0 * intersection + epsilon) / (preds_flat.sum() + targets_flat.sum() + epsilon)\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    dice_sum = 0.0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Dataset returns (image, mask)\n",
    "            images, masks = batch\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            logits = model(images)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).float()\n",
    "\n",
    "            dice = dice_score(preds, masks)\n",
    "            dice_sum += dice.item() * images.size(0)\n",
    "            n += images.size(0)\n",
    "\n",
    "    return dice_sum / max(n, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6f978bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class OvarySideMaskedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wraps a base dataset (UterusDataset or UterusDatasetWithPreprocessing)\n",
    "    and zeros out the half of the image opposite to the annotated ovary.\n",
    "\n",
    "    This mimics the masking we used during training of Model 7.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base = base_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, mask = self.base[idx]  # image, mask: (1, H, W)\n",
    "\n",
    "        # Work on a copy so we don't modify the underlying dataset\n",
    "        image = image.clone()\n",
    "        mask_np = mask[0].numpy()  # (H, W)\n",
    "\n",
    "        if mask_np.sum() > 0:\n",
    "            H, W = mask_np.shape\n",
    "            # x-axis is the second index\n",
    "            xs = np.where(mask_np > 0)[1]\n",
    "            center_x = xs.mean()\n",
    "            if center_x < W / 2:\n",
    "                # ovary on left -> zero out right half\n",
    "                image[:, :, W // 2:] = 0.0\n",
    "            else:\n",
    "                # ovary on right -> zero out left half\n",
    "                image[:, :, :W // 2] = 0.0\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "148ecdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest path: c:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_t2fs_ovary_eligible.csv\n",
      "Loading manifest from c:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_t2fs_ovary_eligible.csv and creating slice map...\n",
      "Slice map created. Found 278 slices containing the uterus.\n",
      "Loading manifest from c:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_t2fs_ovary_eligible.csv and creating slice map...\n",
      "Slice map created. Found 278 slices containing the ovary.\n",
      "Plain val slices: 278\n",
      "RAovSeg val slices: 278\n"
     ]
    }
   ],
   "source": [
    "manifest_path = project_root / \"data\" / \"d2_manifest_t2fs_ovary_eligible.csv\"\n",
    "print(\"Manifest path:\", manifest_path)\n",
    "\n",
    "# Plain preprocessing (min-max normalization)\n",
    "val_dataset_plain = UterusDataset(\n",
    "    manifest_path=str(manifest_path),\n",
    "    image_size=256,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "# RAovSeg-style preprocessing\n",
    "val_dataset_raovseg = UterusDatasetWithPreprocessing(\n",
    "    manifest_path=str(manifest_path),\n",
    "    image_size=256,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "val_loader_plain = DataLoader(val_dataset_plain, batch_size=batch_size, shuffle=False)\n",
    "val_loader_plain_masked = DataLoader(OvarySideMaskedDataset(val_dataset_plain),\n",
    "                                     batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_loader_raovseg = DataLoader(val_dataset_raovseg, batch_size=batch_size, shuffle=False)\n",
    "val_loader_raovseg_masked = DataLoader(OvarySideMaskedDataset(val_dataset_raovseg),\n",
    "                                       batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Plain val slices:\", len(val_dataset_plain))\n",
    "print(\"RAovSeg val slices:\", len(val_dataset_raovseg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7eba1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transfer-learning Attention U-Net with ResNet34 encoder ---\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "\n",
    "class TLAttentionUNetResNet34(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention U-Net style decoder with a ResNet34 encoder.\n",
    "    - Encoder: ResNet34 pretrained on ImageNet (RGB).\n",
    "    - Decoder: 4 upsampling stages with attention gates and DoubleConv blocks.\n",
    "    - Input: (B, 1, H, W); we repeat the channel to 3 for ResNet.\n",
    "    - Output: logits (B, 1, H, W), resized back to input resolution if needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_classes=1, in_channels=1, use_pretrained=True):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        # Try to load pretrained weights; fall back to random init if download fails.\n",
    "        if use_pretrained:\n",
    "            try:\n",
    "                encoder = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "                print(\"Loaded ResNet34 with ImageNet pretrained weights.\")\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"WARNING: Could not load pretrained ResNet34 weights. \"\n",
    "                    \"Falling back to randomly initialized encoder.\\nError:\", e\n",
    "                )\n",
    "                encoder = resnet34(weights=None)\n",
    "        else:\n",
    "            encoder = resnet34(weights=None)\n",
    "            print(\"Using ResNet34 without pretrained weights.\")\n",
    "\n",
    "        self.encoder = encoder\n",
    "\n",
    "        # Encoder parts\n",
    "        self.conv1 = encoder.conv1\n",
    "        self.bn1 = encoder.bn1\n",
    "        self.relu = encoder.relu\n",
    "        self.maxpool = encoder.maxpool\n",
    "\n",
    "        self.layer1 = encoder.layer1  # output: 64 ch, /4\n",
    "        self.layer2 = encoder.layer2  # 128 ch, /8\n",
    "        self.layer3 = encoder.layer3  # 256 ch, /16\n",
    "        self.layer4 = encoder.layer4  # 512 ch, /32\n",
    "\n",
    "        # Decoder with attention gates (mirror the last 4 scales)\n",
    "        # shapes: x1 (64, H/4), x2 (128, H/8), x3 (256, H/16), x4 (512, H/32)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.att1 = AttentionGate(F_g=256, F_l=256, F_int=128)\n",
    "        self.conv1_up = DoubleConv(512, 256)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.att2 = AttentionGate(F_g=128, F_l=128, F_int=64)\n",
    "        self.conv2_up = DoubleConv(256, 128)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.att3 = AttentionGate(F_g=64, F_l=64, F_int=32)\n",
    "        self.conv3_up = DoubleConv(128, 64)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)\n",
    "        self.att4 = AttentionGate(F_g=64, F_l=64, F_int=32)\n",
    "        self.conv4_up = DoubleConv(128, 64)\n",
    "\n",
    "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Remember input spatial size (e.g. 256x256)\n",
    "        input_size = x.size()[2:]\n",
    "\n",
    "        # Repeat channel to 3 for ResNet (if input is 1-channel)\n",
    "        if self.in_channels == 1 and x.size(1) == 1:\n",
    "            x = x.repeat(1, 3, 1, 1)\n",
    "\n",
    "        # Encoder\n",
    "        x0 = self.conv1(x)            # -> (64, H/2, W/2)\n",
    "        x0 = self.bn1(x0)\n",
    "        x0 = self.relu(x0)            # we'll use this as the highest-res skip connection\n",
    "\n",
    "        x1 = self.maxpool(x0)         # -> (64, H/4, W/4)\n",
    "        x1 = self.layer1(x1)          # -> (64, H/4, W/4)\n",
    "        x2 = self.layer2(x1)          # -> (128, H/8, W/8)\n",
    "        x3 = self.layer3(x2)          # -> (256, H/16, W/16)\n",
    "        x4 = self.layer4(x3)          # -> (512, H/32, W/32)\n",
    "\n",
    "        # Decoder with attention\n",
    "        d4 = self.up1(x4)             # (256, H/16, W/16)\n",
    "        x3_att = self.att1(g=d4, x=x3)\n",
    "        d4 = self.conv1_up(torch.cat([d4, x3_att], dim=1))\n",
    "\n",
    "        d3 = self.up2(d4)             # (128, H/8, W/8)\n",
    "        x2_att = self.att2(g=d3, x=x2)\n",
    "        d3 = self.conv2_up(torch.cat([d3, x2_att], dim=1))\n",
    "\n",
    "        d2 = self.up3(d3)             # (64, H/4, W/4)\n",
    "        x1_att = self.att3(g=d2, x=x1)\n",
    "        d2 = self.conv3_up(torch.cat([d2, x1_att], dim=1))\n",
    "\n",
    "        d1 = self.up4(d2)             # (64, H/2, W/2)\n",
    "        x0_att = self.att4(g=d1, x=x0)\n",
    "        d1 = self.conv4_up(torch.cat([d1, x0_att], dim=1))  # (64, H/2, W/2)\n",
    "\n",
    "        out = self.outc(d1)\n",
    "\n",
    "        # Upsample back to original input resolution (256x256)\n",
    "        if out.shape[2:] != input_size:\n",
    "            out = F.interpolate(out, size=input_size, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def freeze_encoder(model: TLAttentionUNetResNet34):\n",
    "    for p in model.encoder.parameters():\n",
    "        p.requires_grad = False\n",
    "    print(\"Encoder frozen (no gradient).\")\n",
    "\n",
    "\n",
    "def unfreeze_encoder(model: TLAttentionUNetResNet34):\n",
    "    for p in model.encoder.parameters():\n",
    "        p.requires_grad = True\n",
    "    print(\"Encoder unfrozen (trainable).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "767e3891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models dir: c:\\Users\\lytten\\programming\\dlvr-project\\models\n"
     ]
    }
   ],
   "source": [
    "models_dir = project_root / \"models\"\n",
    "print(\"Models dir:\", models_dir)\n",
    "\n",
    "include_tl5 = True  # set to False if you don't want to deal with the TL architecture here\n",
    "\n",
    "MODEL_CONFIGS = [\n",
    "    {\n",
    "        \"name\": \"Model 1: U-Net (baseline)\",\n",
    "        \"short\": \"M1_baseline\",\n",
    "        \"ckpt\": \"07_ovary_baseline_best.pth\",\n",
    "        \"arch\": \"unet\",\n",
    "        \"preproc\": \"plain\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 2: Attention U-Net\",\n",
    "        \"short\": \"M2_attn\",\n",
    "        \"ckpt\": \"09_attention_unet_best.pth\",\n",
    "        \"arch\": \"attn\",\n",
    "        \"preproc\": \"plain\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 3: Attn U-Net + RAovSeg (20 ep)\",\n",
    "        \"short\": \"M3_attn_raovseg\",\n",
    "        \"ckpt\": \"11_attention_unet_preprocessed_best.pth\",\n",
    "        \"arch\": \"attn\",\n",
    "        \"preproc\": \"raovseg\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 4: Attn U-Net + RAovSeg (50 ep)\",\n",
    "        \"short\": \"M4_attn_raovseg_long\",\n",
    "        \"ckpt\": \"13_attn_unet_prep_long_best.pth\",\n",
    "        \"arch\": \"attn\",\n",
    "        \"preproc\": \"raovseg\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model 5: Attn U-Net + RAovSeg + FTL\",\n",
    "        \"short\": \"M5_attn_raovseg_ftl\",\n",
    "        \"ckpt\": \"15_attn_unet_focal_tversky_best.pth\",\n",
    "        \"arch\": \"attn\",\n",
    "        \"preproc\": \"raovseg\",\n",
    "    },\n",
    "]\n",
    "\n",
    "if include_tl5:\n",
    "    MODEL_CONFIGS.append(\n",
    "        {\n",
    "            \"name\": \"TL-5: ResNet34 Attn U-Net + RAovSeg + FTL\",\n",
    "            \"short\": \"TL5_resnet34_attn\",\n",
    "            \"ckpt\": \"20_tl_attn_unet_resnet34_ft_best.pth\",\n",
    "            \"arch\": \"resnet34_attn\",\n",
    "            \"preproc\": \"raovseg\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "MODEL_CONFIGS.append(\n",
    "    {\n",
    "        \"name\": \"Model 7: Attn U-Net + RAovSeg + FTL (masked train)\",\n",
    "        \"short\": \"M7_attn_raovseg_ftl_masked\",\n",
    "        \"ckpt\": \"21_attn_unet_prep_ft_masked_best.pth\",\n",
    "        \"arch\": \"attn\",\n",
    "        \"preproc\": \"raovseg\",\n",
    "    }\n",
    ")\n",
    "\n",
    "def create_model(cfg):\n",
    "    arch = cfg[\"arch\"]\n",
    "    if arch == \"unet\":\n",
    "        model = UNet(n_channels=1, n_classes=1)\n",
    "    elif arch == \"attn\":\n",
    "        model = AttentionUNet(n_channels=1, n_classes=1)\n",
    "    elif arch == \"resnet34_attn\":\n",
    "        # use_pretrained=False because the checkpoint already has the trained weights\n",
    "        model = TLAttentionUNetResNet34(n_classes=1, in_channels=1, use_pretrained=False)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown arch: {arch}\")\n",
    "\n",
    "    ckpt_path = models_dir / cfg[\"ckpt\"]\n",
    "    print(f\"  Loading {cfg['name']} from {ckpt_path}\")\n",
    "    state_dict = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e46cb1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Model 1: U-Net (baseline)\n",
      "  Loading Model 1: U-Net (baseline) from c:\\Users\\lytten\\programming\\dlvr-project\\models\\07_ovary_baseline_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lytten\\AppData\\Local\\Temp\\ipykernel_17400\\3140079982.py:79: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Dice (orig):   0.2755\n",
      "  Val Dice (masked): 0.3916\n",
      "  ΔDice (masked-orig): +0.1162\n",
      "================================================================================\n",
      "Model 2: Attention U-Net\n",
      "  Loading Model 2: Attention U-Net from c:\\Users\\lytten\\programming\\dlvr-project\\models\\09_attention_unet_best.pth\n",
      "  Val Dice (orig):   0.2470\n",
      "  Val Dice (masked): 0.3805\n",
      "  ΔDice (masked-orig): +0.1335\n",
      "================================================================================\n",
      "Model 3: Attn U-Net + RAovSeg (20 ep)\n",
      "  Loading Model 3: Attn U-Net + RAovSeg (20 ep) from c:\\Users\\lytten\\programming\\dlvr-project\\models\\11_attention_unet_preprocessed_best.pth\n",
      "  Val Dice (orig):   0.3061\n",
      "  Val Dice (masked): 0.3481\n",
      "  ΔDice (masked-orig): +0.0420\n",
      "================================================================================\n",
      "Model 4: Attn U-Net + RAovSeg (50 ep)\n",
      "  Loading Model 4: Attn U-Net + RAovSeg (50 ep) from c:\\Users\\lytten\\programming\\dlvr-project\\models\\13_attn_unet_prep_long_best.pth\n",
      "  Val Dice (orig):   0.2644\n",
      "  Val Dice (masked): 0.2954\n",
      "  ΔDice (masked-orig): +0.0309\n",
      "================================================================================\n",
      "Model 5: Attn U-Net + RAovSeg + FTL\n",
      "  Loading Model 5: Attn U-Net + RAovSeg + FTL from c:\\Users\\lytten\\programming\\dlvr-project\\models\\15_attn_unet_focal_tversky_best.pth\n",
      "  Val Dice (orig):   0.3128\n",
      "  Val Dice (masked): 0.3437\n",
      "  ΔDice (masked-orig): +0.0309\n",
      "================================================================================\n",
      "TL-5: ResNet34 Attn U-Net + RAovSeg + FTL\n",
      "Using ResNet34 without pretrained weights.\n",
      "  Loading TL-5: ResNet34 Attn U-Net + RAovSeg + FTL from c:\\Users\\lytten\\programming\\dlvr-project\\models\\20_tl_attn_unet_resnet34_ft_best.pth\n",
      "  Val Dice (orig):   0.3645\n",
      "  Val Dice (masked): 0.4204\n",
      "  ΔDice (masked-orig): +0.0559\n",
      "================================================================================\n",
      "Model 7: Attn U-Net + RAovSeg + FTL (masked train)\n",
      "  Loading Model 7: Attn U-Net + RAovSeg + FTL (masked train) from c:\\Users\\lytten\\programming\\dlvr-project\\models\\21_attn_unet_prep_ft_masked_best.pth\n",
      "  Val Dice (orig):   0.2643\n",
      "  Val Dice (masked): 0.3535\n",
      "  ΔDice (masked-orig): +0.0893\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Short</th>\n",
       "      <th>Preproc</th>\n",
       "      <th>Val Dice (orig)</th>\n",
       "      <th>Val Dice (masked)</th>\n",
       "      <th>ΔDice (masked - orig)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1: U-Net (baseline)</td>\n",
       "      <td>M1_baseline</td>\n",
       "      <td>plain</td>\n",
       "      <td>0.275465</td>\n",
       "      <td>0.391648</td>\n",
       "      <td>0.116183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2: Attention U-Net</td>\n",
       "      <td>M2_attn</td>\n",
       "      <td>plain</td>\n",
       "      <td>0.247044</td>\n",
       "      <td>0.380542</td>\n",
       "      <td>0.133497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3: Attn U-Net + RAovSeg (20 ep)</td>\n",
       "      <td>M3_attn_raovseg</td>\n",
       "      <td>raovseg</td>\n",
       "      <td>0.306095</td>\n",
       "      <td>0.348100</td>\n",
       "      <td>0.042005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4: Attn U-Net + RAovSeg (50 ep)</td>\n",
       "      <td>M4_attn_raovseg_long</td>\n",
       "      <td>raovseg</td>\n",
       "      <td>0.264445</td>\n",
       "      <td>0.295393</td>\n",
       "      <td>0.030947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model 5: Attn U-Net + RAovSeg + FTL</td>\n",
       "      <td>M5_attn_raovseg_ftl</td>\n",
       "      <td>raovseg</td>\n",
       "      <td>0.312830</td>\n",
       "      <td>0.343682</td>\n",
       "      <td>0.030853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TL-5: ResNet34 Attn U-Net + RAovSeg + FTL</td>\n",
       "      <td>TL5_resnet34_attn</td>\n",
       "      <td>raovseg</td>\n",
       "      <td>0.364519</td>\n",
       "      <td>0.420374</td>\n",
       "      <td>0.055855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model 7: Attn U-Net + RAovSeg + FTL (masked tr...</td>\n",
       "      <td>M7_attn_raovseg_ftl_masked</td>\n",
       "      <td>raovseg</td>\n",
       "      <td>0.264260</td>\n",
       "      <td>0.353516</td>\n",
       "      <td>0.089256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  \\\n",
       "0                          Model 1: U-Net (baseline)   \n",
       "1                           Model 2: Attention U-Net   \n",
       "2              Model 3: Attn U-Net + RAovSeg (20 ep)   \n",
       "3              Model 4: Attn U-Net + RAovSeg (50 ep)   \n",
       "4                Model 5: Attn U-Net + RAovSeg + FTL   \n",
       "5          TL-5: ResNet34 Attn U-Net + RAovSeg + FTL   \n",
       "6  Model 7: Attn U-Net + RAovSeg + FTL (masked tr...   \n",
       "\n",
       "                        Short  Preproc  Val Dice (orig)  Val Dice (masked)  \\\n",
       "0                 M1_baseline    plain         0.275465           0.391648   \n",
       "1                     M2_attn    plain         0.247044           0.380542   \n",
       "2             M3_attn_raovseg  raovseg         0.306095           0.348100   \n",
       "3        M4_attn_raovseg_long  raovseg         0.264445           0.295393   \n",
       "4         M5_attn_raovseg_ftl  raovseg         0.312830           0.343682   \n",
       "5           TL5_resnet34_attn  raovseg         0.364519           0.420374   \n",
       "6  M7_attn_raovseg_ftl_masked  raovseg         0.264260           0.353516   \n",
       "\n",
       "   ΔDice (masked - orig)  \n",
       "0               0.116183  \n",
       "1               0.133497  \n",
       "2               0.042005  \n",
       "3               0.030947  \n",
       "4               0.030853  \n",
       "5               0.055855  \n",
       "6               0.089256  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for cfg in MODEL_CONFIGS:\n",
    "    print(\"=\" * 80)\n",
    "    print(cfg[\"name\"])\n",
    "    model = create_model(cfg)\n",
    "\n",
    "    if cfg[\"preproc\"] == \"plain\":\n",
    "        dl_orig = val_loader_plain\n",
    "        dl_masked = val_loader_plain_masked\n",
    "    elif cfg[\"preproc\"] == \"raovseg\":\n",
    "        dl_orig = val_loader_raovseg\n",
    "        dl_masked = val_loader_raovseg_masked\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown preproc: {cfg['preproc']}\")\n",
    "\n",
    "    dice_orig = evaluate_model(model, dl_orig)\n",
    "    dice_masked = evaluate_model(model, dl_masked)\n",
    "\n",
    "    delta = dice_masked - dice_orig\n",
    "\n",
    "    print(f\"  Val Dice (orig):   {dice_orig:.4f}\")\n",
    "    print(f\"  Val Dice (masked): {dice_masked:.4f}\")\n",
    "    print(f\"  ΔDice (masked-orig): {delta:+.4f}\")\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": cfg[\"name\"],\n",
    "            \"Short\": cfg[\"short\"],\n",
    "            \"Preproc\": cfg[\"preproc\"],\n",
    "            \"Val Dice (orig)\": dice_orig,\n",
    "            \"Val Dice (masked)\": dice_masked,\n",
    "            \"ΔDice (masked - orig)\": delta,\n",
    "        }\n",
    "    )\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69476ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Model  Val Dice (orig)  \\\n",
      "0                          Model 1: U-Net (baseline)           0.2755   \n",
      "1                           Model 2: Attention U-Net           0.2470   \n",
      "2              Model 3: Attn U-Net + RAovSeg (20 ep)           0.3061   \n",
      "3              Model 4: Attn U-Net + RAovSeg (50 ep)           0.2644   \n",
      "4                Model 5: Attn U-Net + RAovSeg + FTL           0.3128   \n",
      "5          TL-5: ResNet34 Attn U-Net + RAovSeg + FTL           0.3645   \n",
      "6  Model 7: Attn U-Net + RAovSeg + FTL (masked tr...           0.2643   \n",
      "\n",
      "   Val Dice (masked)  ΔDice (masked - orig)  \n",
      "0             0.3916                 0.1162  \n",
      "1             0.3805                 0.1335  \n",
      "2             0.3481                 0.0420  \n",
      "3             0.2954                 0.0309  \n",
      "4             0.3437                 0.0309  \n",
      "5             0.4204                 0.0559  \n",
      "6             0.3535                 0.0893  \n",
      "\n",
      "LaTeX table rows:\n",
      "Model 1: U-Net (baseline) & 0.2755 & 0.3916 & +0.1162 \\\\\n",
      "Model 2: Attention U-Net & 0.2470 & 0.3805 & +0.1335 \\\\\n",
      "Model 3: Attn U-Net + RAovSeg (20 ep) & 0.3061 & 0.3481 & +0.0420 \\\\\n",
      "Model 4: Attn U-Net + RAovSeg (50 ep) & 0.2644 & 0.2954 & +0.0309 \\\\\n",
      "Model 5: Attn U-Net + RAovSeg + FTL & 0.3128 & 0.3437 & +0.0309 \\\\\n",
      "TL-5: ResNet34 Attn U-Net + RAovSeg + FTL & 0.3645 & 0.4204 & +0.0559 \\\\\n",
      "Model 7: Attn U-Net + RAovSeg + FTL (masked train) & 0.2643 & 0.3535 & +0.0893 \\\\\n"
     ]
    }
   ],
   "source": [
    "# Sort roughly by \"pipeline complexity\"\n",
    "order = [\n",
    "    \"M1_baseline\",\n",
    "    \"M2_attn\",\n",
    "    \"M3_attn_raovseg\",\n",
    "    \"M4_attn_raovseg_long\",\n",
    "    \"M5_attn_raovseg_ftl\",\n",
    "    \"TL5_resnet34_attn\" if include_tl5 else None,\n",
    "    \"M7_attn_raovseg_ftl_masked\",\n",
    "]\n",
    "order = [s for s in order if s is not None]\n",
    "\n",
    "results_df_sorted = results_df.set_index(\"Short\").loc[order].reset_index()\n",
    "\n",
    "# Round for nice printing\n",
    "display_cols = [\"Model\", \"Val Dice (orig)\", \"Val Dice (masked)\", \"ΔDice (masked - orig)\"]\n",
    "print(results_df_sorted[display_cols].round(4))\n",
    "\n",
    "# If you want LaTeX:\n",
    "print(\"\\nLaTeX table rows:\")\n",
    "for _, row in results_df_sorted.iterrows():\n",
    "    model_name = row[\"Model\"]\n",
    "    d_orig = row[\"Val Dice (orig)\"]\n",
    "    d_mask = row[\"Val Dice (masked)\"]\n",
    "    delta = row[\"ΔDice (masked - orig)\"]\n",
    "    print(f\"{model_name} & {d_orig:.4f} & {d_mask:.4f} & {delta:+.4f} \\\\\\\\\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvr-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
