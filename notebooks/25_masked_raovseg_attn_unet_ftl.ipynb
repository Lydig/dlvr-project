{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16807e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Notebook 25: Masked RAovSeg + Attention U-Net + Focal Tversky\n",
    "#\n",
    "# New experimental setup:\n",
    "# - Use **ovary-side masked** T2FS volumes (non-ovary half blacked out).\n",
    "# - RAovSeg-style preprocessing and augmentation (from `UterusDatasetWithPreprocessing`).\n",
    "# - Attention U-Net segmentation model.\n",
    "# - Focal Tversky loss (alpha=0.7, beta=0.3, gamma=4/3).\n",
    "# - Train/val/test splits are patient-based, from\n",
    "#   `d2_manifest_t2fs_ov_final_with_split_and_masked.csv`.\n",
    "#\n",
    "# This notebook's goal: get a fully working training/eval loop on the new masked\n",
    "# dataset. Transfer learning (ResNet34 encoder) will be added once this pipeline\n",
    "# is stable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f65eb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\lytten\\programming\\dlvr-project\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make sure we can import from src/\n",
    "project_root = Path(\"..\").resolve()\n",
    "if (project_root / \"src\").exists() and str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src.data_loader import UterusDatasetWithPreprocessing\n",
    "from src.models import AttentionUNet\n",
    "from src.losses import FocalTverskyLoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Project root:\", project_root)\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dedcf6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded final masked manifest: C:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_t2fs_ov_final_with_split_and_masked.csv\n",
      "Columns: ['patient_id', 't2fs_path', 'ov_mask_path', 'split', 't2fs_masked_path']\n",
      "Num patients: 37\n",
      "split\n",
      "train    26\n",
      "val       6\n",
      "test      5\n",
      "Name: count, dtype: int64\n",
      "Train patients: 26\n",
      "Val patients: 6\n",
      "Test patients: 5\n",
      "Saved RAovSeg manifest: C:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_masked_raovseg_train.csv (n=26)\n",
      "Saved RAovSeg manifest: C:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_masked_raovseg_val.csv (n=6)\n",
      "Saved RAovSeg manifest: C:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_masked_raovseg_test.csv (n=5)\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Build RAovSeg manifests from the final masked manifest\n",
    "\n",
    "# %%\n",
    "data_dir = project_root / \"data\"\n",
    "final_masked_manifest_path = data_dir / \"d2_manifest_t2fs_ov_final_with_split_and_masked.csv\"\n",
    "\n",
    "final_df = pd.read_csv(final_masked_manifest_path)\n",
    "print(\"Loaded final masked manifest:\", final_masked_manifest_path)\n",
    "print(\"Columns:\", final_df.columns.tolist())\n",
    "print(\"Num patients:\", len(final_df))\n",
    "print(final_df[\"split\"].value_counts())\n",
    "\n",
    "# We want RAovSeg-style manifests with columns: patient_id, mri_path, mask_path\n",
    "def make_raovseg_manifest(df_split, out_path):\n",
    "    df_local = df_split.copy()\n",
    "    # Use masked T2FS as the MRI image\n",
    "    df_local[\"mri_path\"] = df_local[\"t2fs_masked_path\"]\n",
    "    df_local[\"mask_path\"] = df_local[\"ov_mask_path\"]\n",
    "\n",
    "    # Keep only needed columns for the dataset class\n",
    "    out_df = df_local[[\"patient_id\", \"mri_path\", \"mask_path\"]].copy()\n",
    "\n",
    "    # Ensure paths are relative to project_root (if they aren't already)\n",
    "    def normalize_path(p):\n",
    "        p = Path(p)\n",
    "        if p.is_absolute():\n",
    "            try:\n",
    "                return str(p.relative_to(project_root))\n",
    "            except ValueError:\n",
    "                return str(p)  # fallback\n",
    "        else:\n",
    "            return str(p)\n",
    "\n",
    "    out_df[\"mri_path\"] = out_df[\"mri_path\"].apply(normalize_path)\n",
    "    out_df[\"mask_path\"] = out_df[\"mask_path\"].apply(normalize_path)\n",
    "\n",
    "    out_df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved RAovSeg manifest: {out_path} (n={len(out_df)})\")\n",
    "\n",
    "# Split by patient\n",
    "train_df = final_df[final_df[\"split\"] == \"train\"]\n",
    "val_df   = final_df[final_df[\"split\"] == \"val\"]\n",
    "test_df  = final_df[final_df[\"split\"] == \"test\"]\n",
    "\n",
    "print(\"Train patients:\", len(train_df))\n",
    "print(\"Val patients:\",   len(val_df))\n",
    "print(\"Test patients:\",  len(test_df))\n",
    "\n",
    "# Output paths\n",
    "train_manifest_raovseg = data_dir / \"d2_manifest_masked_raovseg_train.csv\"\n",
    "val_manifest_raovseg   = data_dir / \"d2_manifest_masked_raovseg_val.csv\"\n",
    "test_manifest_raovseg  = data_dir / \"d2_manifest_masked_raovseg_test.csv\"\n",
    "\n",
    "make_raovseg_manifest(train_df, train_manifest_raovseg)\n",
    "make_raovseg_manifest(val_df,   val_manifest_raovseg)\n",
    "make_raovseg_manifest(test_df,  test_manifest_raovseg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83456750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading masked RAovSeg datasets ---\n",
      "Loading manifest from C:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_masked_raovseg_train.csv and creating slice map...\n",
      "Slice map created. Found 0 slices containing the ovary.\n",
      "Loading manifest from C:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_masked_raovseg_val.csv and creating slice map...\n",
      "Slice map created. Found 0 slices containing the ovary.\n",
      "Loading manifest from C:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_masked_raovseg_test.csv and creating slice map...\n",
      "Slice map created. Found 0 slices containing the ovary.\n",
      "\n",
      "Dataset sizes (ovary-positive slices):\n",
      "Train slices: 0\n",
      "Val slices:   0\n",
      "Test slices:  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal slices:  \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(val_dataset))\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest slices: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test_dataset))\n\u001b[1;32m---> 33\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m val_loader   \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset,   batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mnum_workers)\n\u001b[0;32m     35\u001b[0m test_loader  \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset,  batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mnum_workers)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dlvr-project\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dlvr-project\\lib\\site-packages\\torch\\utils\\data\\sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Datasets and DataLoaders (masked + RAovSeg preprocessing)\n",
    "\n",
    "# %%\n",
    "image_size = 256\n",
    "batch_size = 1   # 1070 GPU constraint\n",
    "num_workers = 0  # keep it simple / Windows-friendly\n",
    "\n",
    "print(\"--- Loading masked RAovSeg datasets ---\")\n",
    "train_dataset = UterusDatasetWithPreprocessing(\n",
    "    manifest_path=str(train_manifest_raovseg),\n",
    "    image_size=image_size,\n",
    "    augment=True,\n",
    ")\n",
    "\n",
    "val_dataset = UterusDatasetWithPreprocessing(\n",
    "    manifest_path=str(val_manifest_raovseg),\n",
    "    image_size=image_size,\n",
    "    augment=False,\n",
    ")\n",
    "\n",
    "test_dataset = UterusDatasetWithPreprocessing(\n",
    "    manifest_path=str(test_manifest_raovseg),\n",
    "    image_size=image_size,\n",
    "    augment=False,\n",
    ")\n",
    "\n",
    "print(\"\\nDataset sizes (ovary-positive slices):\")\n",
    "print(\"Train slices:\", len(train_dataset))\n",
    "print(\"Val slices:  \", len(val_dataset))\n",
    "print(\"Test slices: \", len(test_dataset))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4dd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RAovSeg manifest: C:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_masked_raovseg_train.csv\n",
      "Columns: ['patient_id', 'mri_path', 'mask_path']\n",
      "Num rows: 26\n",
      "  patient_id                                           mri_path  \\\n",
      "0     D2-051  data\\UT-EndoMRI\\D2_TCPW_masked\\D2-051\\D2-051_T...   \n",
      "1     D2-027  data\\UT-EndoMRI\\D2_TCPW_masked\\D2-027\\D2-027_T...   \n",
      "2     D2-048  data\\UT-EndoMRI\\D2_TCPW_masked\\D2-048\\D2-048_T...   \n",
      "3     D2-014  data\\UT-EndoMRI\\D2_TCPW_masked\\D2-014\\D2-014_T...   \n",
      "4     D2-012  data\\UT-EndoMRI\\D2_TCPW_masked\\D2-012\\D2-012_T...   \n",
      "\n",
      "                                         mask_path  \n",
      "0  data\\UT-EndoMRI\\D2_TCPW\\D2-001\\D2-001_ov.nii.gz  \n",
      "1  data\\UT-EndoMRI\\D2_TCPW\\D2-005\\D2-005_ov.nii.gz  \n",
      "2  data\\UT-EndoMRI\\D2_TCPW\\D2-007\\D2-007_ov.nii.gz  \n",
      "3  data\\UT-EndoMRI\\D2_TCPW\\D2-010\\D2-010_ov.nii.gz  \n",
      "4  data\\UT-EndoMRI\\D2_TCPW\\D2-012\\D2-012_ov.nii.gz  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "project_root = Path(\"..\").resolve()\n",
    "data_dir = project_root / \"data\"\n",
    "\n",
    "train_manifest_raovseg = data_dir / \"d2_manifest_masked_raovseg_train.csv\"\n",
    "print(\"Train RAovSeg manifest:\", train_manifest_raovseg)\n",
    "\n",
    "df_train = pd.read_csv(train_manifest_raovseg)\n",
    "print(\"Columns:\", df_train.columns.tolist())\n",
    "print(\"Num rows:\", len(df_train))\n",
    "print(df_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12200a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 0: patient_id                                               D2-051\n",
      "mri_path      data\\UT-EndoMRI\\D2_TCPW_masked\\D2-051\\D2-051_T...\n",
      "mask_path       data\\UT-EndoMRI\\D2_TCPW\\D2-001\\D2-001_ov.nii.gz\n",
      "Name: 0, dtype: object\n",
      "Resolved mask path: C:\\Users\\lytten\\programming\\dlvr-project\\data\\UT-EndoMRI\\D2_TCPW\\D2-001\\D2-001_ov.nii.gz\n",
      "Mask shape: (320, 320, 34)\n",
      "Mask min / max: 0.0 1.0\n",
      "Num voxels > 0: 1039\n"
     ]
    }
   ],
   "source": [
    "row0 = df_train.iloc[0]\n",
    "print(\"\\nRow 0:\", row0)\n",
    "\n",
    "mask_path = Path(row0[\"mask_path\"])\n",
    "if not mask_path.is_absolute():\n",
    "    mask_path = project_root / mask_path\n",
    "\n",
    "print(\"Resolved mask path:\", mask_path)\n",
    "assert mask_path.exists(), \"Mask file does not exist!\"\n",
    "\n",
    "msk = nib.load(str(mask_path)).get_fdata()\n",
    "print(\"Mask shape:\", msk.shape)\n",
    "print(\"Mask min / max:\", float(msk.min()), float(msk.max()))\n",
    "print(\"Num voxels > 0:\", int((msk > 0).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ebce5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading masked RAovSeg datasets ---\n",
      "Loading manifest from C:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_masked_raovseg_train.csv and creating slice map...\n",
      "Slice map created. Found 0 slices containing the ovary.\n",
      "Loading manifest from C:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_masked_raovseg_val.csv and creating slice map...\n",
      "Slice map created. Found 0 slices containing the ovary.\n",
      "Loading manifest from C:\\Users\\lytten\\programming\\dlvr-project\\data\\d2_manifest_masked_raovseg_test.csv and creating slice map...\n",
      "Slice map created. Found 0 slices containing the ovary.\n",
      "\n",
      "Dataset sizes (ovary-positive slices):\n",
      "Train slices: 0\n",
      "Val slices:   0\n",
      "Test slices:  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal slices:  \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(val_dataset))\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest slices: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test_dataset))\n\u001b[1;32m---> 33\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m val_loader   \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset,   batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mnum_workers)\n\u001b[0;32m     35\u001b[0m test_loader  \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset,  batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mnum_workers)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dlvr-project\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\dlvr-project\\lib\\site-packages\\torch\\utils\\data\\sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Datasets and DataLoaders (masked + RAovSeg preprocessing)\n",
    "\n",
    "# %%\n",
    "image_size = 256\n",
    "batch_size = 1   # 1070 GPU constraint\n",
    "num_workers = 0  # keep it simple / Windows-friendly\n",
    "\n",
    "print(\"--- Loading masked RAovSeg datasets ---\")\n",
    "train_dataset = UterusDatasetWithPreprocessing(\n",
    "    manifest_path=str(train_manifest_raovseg),\n",
    "    image_size=image_size,\n",
    "    augment=True,\n",
    ")\n",
    "\n",
    "val_dataset = UterusDatasetWithPreprocessing(\n",
    "    manifest_path=str(val_manifest_raovseg),\n",
    "    image_size=image_size,\n",
    "    augment=False,\n",
    ")\n",
    "\n",
    "test_dataset = UterusDatasetWithPreprocessing(\n",
    "    manifest_path=str(test_manifest_raovseg),\n",
    "    image_size=image_size,\n",
    "    augment=False,\n",
    ")\n",
    "\n",
    "print(\"\\nDataset sizes (ovary-positive slices):\")\n",
    "print(\"Train slices:\", len(train_dataset))\n",
    "print(\"Val slices:  \", len(val_dataset))\n",
    "print(\"Test slices: \", len(test_dataset))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Model, loss, optimizer\n",
    "\n",
    "# %%\n",
    "n_channels = 1  # single-channel T2FS\n",
    "n_classes  = 1  # ovary vs background\n",
    "\n",
    "model = AttentionUNet(n_channels=n_channels, n_classes=n_classes).to(device)\n",
    "\n",
    "criterion = FocalTverskyLoss(alpha=0.7, beta=0.3, gamma=4/3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ea82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Training and validation loops (Dice metric)\n",
    "\n",
    "# %%\n",
    "def dice_score(preds, targets, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    preds, targets: tensors of shape [B, 1, H, W], values in [0,1].\n",
    "    \"\"\"\n",
    "    preds_flat = preds.view(-1)\n",
    "    targets_flat = targets.view(-1)\n",
    "\n",
    "    intersection = (preds_flat * targets_flat).sum()\n",
    "    return (2. * intersection + epsilon) / (preds_flat.sum() + targets_flat.sum() + epsilon)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, masks in loader:\n",
    "        images = images.to(device)  # [B, 1, H, W]\n",
    "        masks  = masks.to(device)   # [B, 1, H, W]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)              # [B, 1, H, W]\n",
    "        probs  = torch.sigmoid(logits)\n",
    "        loss   = criterion(probs, masks)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_dice = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in loader:\n",
    "            images = images.to(device)\n",
    "            masks  = masks.to(device)\n",
    "\n",
    "            logits = model(images)\n",
    "            probs  = torch.sigmoid(logits)\n",
    "            loss   = criterion(probs, masks)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_dice += dice_score(probs, masks).item() * images.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(loader.dataset)\n",
    "    avg_dice = running_dice / len(loader.dataset)\n",
    "    return avg_loss, avg_dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db87d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Train the masked RAovSeg + Attention U-Net + Focal Tversky model\n",
    "\n",
    "# %%\n",
    "num_epochs = 10  # start with 10 for sanity; bump to 50 once you're happy\n",
    "\n",
    "best_val_dice = -1.0\n",
    "best_epoch = -1\n",
    "\n",
    "model_dir = project_root / \"models\"\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "best_model_path = model_dir / \"25_masked_attn_unet_raovseg_ftl_best.pth\"\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "val_dice_history = []\n",
    "\n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_dice = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    train_loss_history.append(train_loss)\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_dice_history.append(val_dice)\n",
    "\n",
    "    if val_dice > best_val_dice:\n",
    "        best_val_dice = val_dice\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        improved = \"*\"\n",
    "    else:\n",
    "        improved = \" \"\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:02d}/{num_epochs:02d} \"\n",
    "        f\"TrainLoss={train_loss:.4f}  ValLoss={val_loss:.4f}  ValDice={val_dice:.4f}  {improved}\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nBest val Dice: {best_val_dice:.4f} at epoch {best_epoch+1}\")\n",
    "print(\"Saved best model to:\", best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2528e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Training curves\n",
    "\n",
    "# %%\n",
    "epochs = range(1, len(train_loss_history) + 1)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, train_loss_history, label=\"Train loss\")\n",
    "plt.plot(epochs, val_loss_history, label=\"Val loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Focal Tversky loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, val_dice_history, label=\"Val Dice\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Dice\")\n",
    "plt.legend()\n",
    "plt.title(\"Validation Dice\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51507534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Final evaluation on the test set (masked, RAovSeg-preprocessed)\n",
    "\n",
    "# %%\n",
    "# Reload best model\n",
    "best_model = AttentionUNet(n_channels=n_channels, n_classes=n_classes).to(device)\n",
    "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "\n",
    "test_loss, test_dice = evaluate(best_model, test_loader, criterion, device)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test Dice: {test_dice:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvr-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
