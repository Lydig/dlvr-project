{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e00acff",
   "metadata": {},
   "source": [
    "# Experiment 07: ResNet Slice Classifier (ResClass)\n",
    "\n",
    "This notebook implements the first stage of the RAovSeg pipeline: the slice selection classifier. The goal is to train a ResNet-18 model to distinguish between MRI slices that contain an ovary and those that do not.\n",
    "\n",
    "### **Model Configuration**\n",
    "\n",
    "*   **Objective**: Train a binary classifier to identify ovary-containing slices.\n",
    "*   **Model Architecture**: **ResNet-18** (from `torchvision.models`).\n",
    "*   **Dataset**: D2_TCPW, using **all slices** from eligible patients, with binary labels (1=ovary, 0=no ovary).\n",
    "*   **Preprocessing**: RAovSeg custom preprocessing.\n",
    "*   **Data Augmentation**: Simple `RandomAffine` and `RandomHorizontalFlip`.\n",
    "*   **Loss Function**: **`BCEWithLogitsLoss`** (standard for binary classification).\n",
    "*   **Optimizer**: Adam.\n",
    "*   **Learning Rate**: 1e-4 (constant).\n",
    "*   **Epochs**: 20.\n",
    "*   **Batch Size**: **16** (we can use a larger batch size for classification).\n",
    "*   **Image Size**: 256x256.\n",
    "*   **Data Split**: 80% train / 20% validation, split by patient ID.\n",
    "*   **Class Imbalance Strategy**: Subsampling negative examples to a 2:1 ratio (negative:positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3bffdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Full Slice Data for Classification ---\n",
      "Loading manifest from ../data/d2_manifest_t2fs_ovary_eligible.csv and creating slice map for classifier...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 35 is out of bounds for axis 0 with size 35",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Loading Full Slice Data for Classification ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Use the new dataset class which loads positive and negative samples\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m train_full_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSliceClassifierDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanifest_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanifest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m val_full_dataset \u001b[38;5;241m=\u001b[39m SliceClassifierDataset(manifest_path\u001b[38;5;241m=\u001b[39mmanifest_path, image_size\u001b[38;5;241m=\u001b[39mimage_size, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# This split is now on the slice level, but the underlying patient IDs are still separated by the dataset object creation.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# For simplicity, we'll split the shuffled list of slices.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lytten\\programming\\dlvr-project\\src\\data_loader.py:230\u001b[0m, in \u001b[0;36mSliceClassifierDataset.__init__\u001b[1;34m(self, manifest_path, image_size, augment, negative_to_positive_ratio)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m slice_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_slices):\n\u001b[0;32m    226\u001b[0m     sample_info \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmri_path\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmri_path\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m    228\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslice_index\u001b[39m\u001b[38;5;124m'\u001b[39m: slice_index\n\u001b[0;32m    229\u001b[0m     }\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mmask_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslice_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    231\u001b[0m         positive_samples\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msample_info, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m})\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 35 is out of bounds for axis 0 with size 35"
     ]
    }
   ],
   "source": [
    "# --- Imports and Setup ---\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# <--- Import our new Dataset class ---\n",
    "from src.data_loader import SliceClassifierDataset\n",
    "\n",
    "# --- Configuration ---\n",
    "manifest_path = '../data/d2_manifest_t2fs_ovary_eligible.csv'\n",
    "image_size = 256\n",
    "batch_size = 16 # We can use a larger batch size for classification\n",
    "num_epochs = 20\n",
    "lr = 1e-4\n",
    "\n",
    "# --- Data Loading ---\n",
    "print(\"--- Loading Full Slice Data for Classification ---\")\n",
    "# Use the new dataset class which loads positive and negative samples\n",
    "train_full_dataset = SliceClassifierDataset(manifest_path=manifest_path, image_size=image_size, augment=True)\n",
    "val_full_dataset = SliceClassifierDataset(manifest_path=manifest_path, image_size=image_size, augment=False)\n",
    "\n",
    "# This split is now on the slice level, but the underlying patient IDs are still separated by the dataset object creation.\n",
    "# For simplicity, we'll split the shuffled list of slices.\n",
    "num_slices = len(train_full_dataset.slice_data)\n",
    "split_idx = int(num_slices * 0.8)\n",
    "\n",
    "# Note: This is a simplified split. A more rigorous approach would split patient IDs first.\n",
    "# But since the data is shuffled, this is a reasonable starting point.\n",
    "train_dataset = Subset(train_full_dataset, range(split_idx))\n",
    "val_dataset = Subset(val_full_dataset, range(split_idx, num_slices))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "print(f\"Data successfully split:\\nTraining samples: {len(train_dataset)}\\nValidation samples: {len(val_dataset)}\")\n",
    "\n",
    "\n",
    "# --- Training and Validation Functions for CLASSIFICATION ---\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return running_loss / len(loader.dataset), accuracy\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device).unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    \n",
    "    return running_loss / len(loader.dataset), accuracy, precision, recall\n",
    "\n",
    "# --- Main Training Loop ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# Load a pretrained ResNet-18 and adapt it for our single-channel, binary task\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "# Modify for single-channel input\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "# Modify for binary output\n",
    "model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCEWithLogitsLoss() # Standard loss for binary classification\n",
    "\n",
    "train_loss_history, val_loss_history, val_acc_history = [], [], []\n",
    "best_val_acc = -1.0\n",
    "best_epoch = -1\n",
    "model_save_path = \"../models/17_resclass_best.pth\"\n",
    "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "\n",
    "print(\"\\n--- Starting ResNet Classifier (ResClass) Training ---\")\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc, val_prec, val_recall = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    train_loss_history.append(train_loss)\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_acc_history.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} -> Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_recall:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"  -> New best model saved at epoch {best_epoch} with Val Acc: {best_val_acc:.4f}\")\n",
    "\n",
    "print(\"--- Finished Training ---\")\n",
    "print(f\"Best model was from epoch {best_epoch} with a validation accuracy of {best_val_acc:.4f}\")\n",
    "print(f\"Model saved to {model_save_path}\\n\")\n",
    "\n",
    "# --- Visualization ---\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_loss_history, label='Training Loss', marker='.')\n",
    "plt.plot(range(1, num_epochs + 1), val_loss_history, label='Validation Loss', marker='.')\n",
    "plt.title('Training and Validation Loss (ResClass)')\n",
    "plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), val_acc_history, label='Validation Accuracy', color='green', marker='.')\n",
    "plt.title('Validation Accuracy (ResClass)')\n",
    "plt.xlabel('Epochs'); plt.ylabel('Accuracy')\n",
    "plt.axvline(x=best_epoch, color='r', linestyle='--', label=f'Best Acc @ Epoch {best_epoch}')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.suptitle('ResNet Classifier (ResClass) Results', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvr-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
