{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b91aaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in cuda mode.\n",
      "\n",
      "================ FOLD 0 ================\n",
      "Train: [2, 3, 4], Val: 1, Test: 0\n",
      "\n",
      "--- Training Fold 0 ---\n",
      "  Ep 10/100 | Loss: 1.2558 | Val Dice: 0.5020\n",
      "  Ep 20/100 | Loss: 1.1939 | Val Dice: 0.4410\n",
      "  Ep 30/100 | Loss: 1.1365 | Val Dice: 0.5854\n",
      "  Ep 40/100 | Loss: 1.0916 | Val Dice: 0.5330\n",
      "  Ep 50/100 | Loss: 1.0494 | Val Dice: 0.5420\n",
      "  Early stopping at epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lytten\\AppData\\Local\\Temp\\ipykernel_11604\\2917986275.py:312: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Optimizing parameters on Validation Set...\n",
      "  Best Params found: Thresh=0.7, KeepLargest=True (Val Dice: 0.5333)\n",
      "  Evaluating on Test Set with best params...\n",
      "RESULT FOLD 0: Test Dice = 0.5085 ± 0.0654\n",
      "\n",
      "================ FOLD 1 ================\n",
      "Train: [0, 3, 4], Val: 2, Test: 1\n",
      "\n",
      "--- Training Fold 1 ---\n",
      "  Ep 10/100 | Loss: 1.2867 | Val Dice: 0.3437\n",
      "  Ep 20/100 | Loss: 1.2276 | Val Dice: 0.4673\n",
      "  Ep 30/100 | Loss: 1.1854 | Val Dice: 0.4102\n",
      "  Ep 40/100 | Loss: 1.1438 | Val Dice: 0.3138\n",
      "  Ep 50/100 | Loss: 1.1076 | Val Dice: 0.2750\n",
      "  Ep 60/100 | Loss: 1.0704 | Val Dice: 0.5322\n",
      "  Early stopping at epoch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lytten\\AppData\\Local\\Temp\\ipykernel_11604\\2917986275.py:312: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Optimizing parameters on Validation Set...\n",
      "  Best Params found: Thresh=0.5, KeepLargest=True (Val Dice: 0.4970)\n",
      "  Evaluating on Test Set with best params...\n",
      "RESULT FOLD 1: Test Dice = 0.4787 ± 0.3072\n",
      "\n",
      "================ FOLD 2 ================\n",
      "Train: [0, 1, 4], Val: 3, Test: 2\n",
      "\n",
      "--- Training Fold 2 ---\n",
      "  Ep 10/100 | Loss: 1.2999 | Val Dice: 0.0000\n",
      "  Ep 20/100 | Loss: 1.2307 | Val Dice: 0.4392\n",
      "  Ep 30/100 | Loss: 1.1737 | Val Dice: 0.4202\n",
      "  Ep 40/100 | Loss: 1.1269 | Val Dice: 0.4493\n",
      "  Ep 50/100 | Loss: 1.0911 | Val Dice: 0.4011\n",
      "  Ep 60/100 | Loss: 1.0373 | Val Dice: 0.6394\n",
      "  Ep 70/100 | Loss: 0.9964 | Val Dice: 0.5407\n",
      "  Ep 80/100 | Loss: 0.9500 | Val Dice: 0.5884\n",
      "  Early stopping at epoch 87\n",
      "  Optimizing parameters on Validation Set...\n",
      "  Best Params found: Thresh=0.6, KeepLargest=True (Val Dice: 0.6777)\n",
      "  Evaluating on Test Set with best params...\n",
      "RESULT FOLD 2: Test Dice = 0.4294 ± 0.2658\n",
      "\n",
      "================ FOLD 3 ================\n",
      "Train: [0, 1, 2], Val: 4, Test: 3\n",
      "\n",
      "--- Training Fold 3 ---\n",
      "  Ep 10/100 | Loss: 1.3354 | Val Dice: 0.0000\n",
      "  Ep 20/100 | Loss: 1.2729 | Val Dice: 0.2911\n",
      "  Ep 30/100 | Loss: 1.2133 | Val Dice: 0.3561\n",
      "  Ep 40/100 | Loss: 1.1649 | Val Dice: 0.1976\n",
      "  Ep 50/100 | Loss: 1.1199 | Val Dice: 0.3900\n",
      "  Ep 60/100 | Loss: 1.0792 | Val Dice: 0.4315\n",
      "  Ep 70/100 | Loss: 1.0420 | Val Dice: 0.1045\n",
      "  Ep 80/100 | Loss: 0.9997 | Val Dice: 0.4635\n",
      "  Ep 90/100 | Loss: 0.9616 | Val Dice: 0.3724\n",
      "  Ep 100/100 | Loss: 0.9180 | Val Dice: 0.4113\n",
      "  Optimizing parameters on Validation Set...\n",
      "  Best Params found: Thresh=0.3, KeepLargest=True (Val Dice: 0.4660)\n",
      "  Evaluating on Test Set with best params...\n",
      "RESULT FOLD 3: Test Dice = 0.6887 ± 0.0832\n",
      "\n",
      "================ FOLD 4 ================\n",
      "Train: [1, 2, 3], Val: 0, Test: 4\n",
      "\n",
      "--- Training Fold 4 ---\n",
      "  Ep 10/100 | Loss: 1.2109 | Val Dice: 0.2611\n",
      "  Ep 20/100 | Loss: 1.1474 | Val Dice: 0.4517\n",
      "  Ep 30/100 | Loss: 1.0990 | Val Dice: 0.4248\n",
      "  Ep 40/100 | Loss: 1.0550 | Val Dice: 0.4863\n",
      "  Ep 50/100 | Loss: 1.0171 | Val Dice: 0.5225\n",
      "  Ep 60/100 | Loss: 0.9776 | Val Dice: 0.5684\n",
      "  Ep 70/100 | Loss: 0.9346 | Val Dice: 0.5494\n",
      "  Ep 80/100 | Loss: 0.8923 | Val Dice: 0.5509\n",
      "  Ep 90/100 | Loss: 0.8442 | Val Dice: 0.5649\n",
      "  Ep 100/100 | Loss: 0.7874 | Val Dice: 0.5659\n",
      "  Optimizing parameters on Validation Set...\n",
      "  Best Params found: Thresh=0.7, KeepLargest=True (Val Dice: 0.5810)\n",
      "  Evaluating on Test Set with best params...\n",
      "RESULT FOLD 4: Test Dice = 0.4895 ± 0.2273\n",
      "\n",
      "\n",
      "=== DONE ===\n",
      "   fold  test_dice  test_std  best_thresh  use_pp\n",
      "0     0   0.508516  0.065375          0.7    True\n",
      "1     1   0.478736  0.307226          0.5    True\n",
      "2     2   0.429357  0.265760          0.6    True\n",
      "3     3   0.688654  0.083228          0.3    True\n",
      "4     4   0.489469  0.227282          0.7    True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "from tqdm.auto import tqdm\n",
    "from skimage import measure\n",
    "import gc\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DEBUG = False  # <--- SET TO FALSE FOR THE OVERNIGHT RUN\n",
    "\n",
    "CONFIG = {\n",
    "    \"experiment_name\": \"Exp08_Final_5Fold_CV\",\n",
    "    \"image_size\": 256,\n",
    "    \"batch_size\": 12,\n",
    "    \"num_workers\": 0,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"epochs\": 1 if DEBUG else 100,           # 1 epoch for debug, 100 for real\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"seed\": 42,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"manifest_path\": \"../data/UT-EndoMRI/D2_Half_Split/d2_half_split_manifest.csv\",\n",
    "    \"data_root\": \"../data/UT-EndoMRI/D2_Half_Split\",\n",
    "    \"save_dir\": \"../models/final_5fold_results\"\n",
    "}\n",
    "\n",
    "# Create save directory\n",
    "Path(CONFIG[\"save_dir\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Running in {CONFIG['device']} mode.\")\n",
    "if DEBUG:\n",
    "    print(\"WARNING: DEBUG MODE IS ON. Training will be fake.\")\n",
    "\n",
    "# --- UTILS ---\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(CONFIG[\"seed\"])\n",
    "\n",
    "# --- DATASET ---\n",
    "class OvaryDataset(Dataset):\n",
    "    def __init__(self, root_dir, df, image_size=256, augment=False, debug=False):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        \n",
    "        # In DEBUG mode, slice the dataframe to just 2 patients to be fast\n",
    "        if debug:\n",
    "            unique_pids = self.df['pid'].unique()[:2]\n",
    "            self.df = self.df[self.df['pid'].isin(unique_pids)].reset_index(drop=True)\n",
    "            \n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "        self.samples = []\n",
    "        \n",
    "        # Pre-scan for valid slices (where mask > 0)\n",
    "        # This might take a minute per fold, but ensures cleaner training\n",
    "        for idx, row in self.df.iterrows():\n",
    "            img_p = self.root_dir / Path(row['t2fs_path']).name\n",
    "            msk_p = self.root_dir / Path(row['ov_path']).name\n",
    "            \n",
    "            if not img_p.exists(): continue\n",
    "            \n",
    "            try:\n",
    "                # Fast header check or just load\n",
    "                msk_vol = nib.load(str(msk_p)).get_fdata()\n",
    "                # Find slices with content\n",
    "                z_sums = np.sum(msk_vol, axis=(0, 1))\n",
    "                valid_slices = np.where(z_sums > 0)[0]\n",
    "                \n",
    "                for z in valid_slices:\n",
    "                    self.samples.append({\n",
    "                        'img_path': str(img_p),\n",
    "                        'msk_path': str(msk_p),\n",
    "                        'slice_idx': z,\n",
    "                        'pid': row['pid']\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                # In debug we might ignore errors, in prod we want to know\n",
    "                pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        info = self.samples[idx]\n",
    "        \n",
    "        # Load data\n",
    "        img_vol = nib.load(info['img_path']).get_fdata()\n",
    "        msk_vol = nib.load(info['msk_path']).get_fdata()\n",
    "        z = info['slice_idx']\n",
    "        \n",
    "        img = img_vol[:, :, z]\n",
    "        msk = msk_vol[:, :, z]\n",
    "        \n",
    "        # Preprocessing (Standard Min-Max)\n",
    "        p1 = np.percentile(img, 1)\n",
    "        p99 = np.percentile(img, 99)\n",
    "        img = np.clip(img, p1, p99)\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "        \n",
    "        msk = (msk > 0).astype(np.float32)\n",
    "        \n",
    "        # To Tensor (C, H, W)\n",
    "        img = torch.from_numpy(img.T).float().unsqueeze(0)\n",
    "        msk = torch.from_numpy(msk.T).float().unsqueeze(0)\n",
    "        \n",
    "        # Resize\n",
    "        img = TF.resize(img, [self.image_size, self.image_size], interpolation=T.InterpolationMode.BILINEAR, antialias=True)\n",
    "        msk = TF.resize(msk, [self.image_size, self.image_size], interpolation=T.InterpolationMode.NEAREST, antialias=True)\n",
    "        \n",
    "        # Augmentation\n",
    "        if self.augment:\n",
    "            angle = random.uniform(-25, 25)\n",
    "            img = TF.rotate(img, angle, interpolation=T.InterpolationMode.BILINEAR)\n",
    "            msk = TF.rotate(msk, angle, interpolation=T.InterpolationMode.NEAREST)\n",
    "            \n",
    "            max_shift = int(self.image_size * 0.1)\n",
    "            t_x = random.randint(-max_shift, max_shift)\n",
    "            t_y = random.randint(-max_shift, max_shift)\n",
    "            img = TF.affine(img, angle=0, translate=(t_x, t_y), scale=1.0, shear=0, interpolation=T.InterpolationMode.BILINEAR)\n",
    "            msk = TF.affine(msk, angle=0, translate=(t_x, t_y), scale=1.0, shear=0, interpolation=T.InterpolationMode.NEAREST)\n",
    "            \n",
    "        return img, msk\n",
    "\n",
    "# --- MODEL (Attention U-Net) ---\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionGate, self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class AttentionUNet(nn.Module):\n",
    "    def __init__(self, n_channels=1, n_classes=1):\n",
    "        super(AttentionUNet, self).__init__()\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(64, 128))\n",
    "        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(128, 256))\n",
    "        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(256, 512))\n",
    "        self.down4 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(512, 1024))\n",
    "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.att1 = AttentionGate(F_g=512, F_l=512, F_int=256)\n",
    "        self.conv1 = DoubleConv(1024, 512)\n",
    "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.att2 = AttentionGate(F_g=256, F_l=256, F_int=128)\n",
    "        self.conv2 = DoubleConv(512, 256)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.att3 = AttentionGate(F_g=128, F_l=128, F_int=64)\n",
    "        self.conv3 = DoubleConv(256, 128)\n",
    "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.att4 = AttentionGate(F_g=64, F_l=64, F_int=32)\n",
    "        self.conv4 = DoubleConv(128, 64)\n",
    "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s1 = self.inc(x)\n",
    "        s2 = self.down1(s1)\n",
    "        s3 = self.down2(s2)\n",
    "        s4 = self.down3(s3)\n",
    "        s5 = self.down4(s4)\n",
    "        d4 = self.up1(s5)\n",
    "        s4_att = self.att1(g=d4, x=s4)\n",
    "        d4 = torch.cat([d4, s4_att], dim=1)\n",
    "        d4 = self.conv1(d4)\n",
    "        d3 = self.up2(d4)\n",
    "        s3_att = self.att2(g=d3, x=s3)\n",
    "        d3 = torch.cat([d3, s3_att], dim=1)\n",
    "        d3 = self.conv2(d3)\n",
    "        d2 = self.up3(d3)\n",
    "        s2_att = self.att3(g=d2, x=s2)\n",
    "        d2 = torch.cat([d2, s2_att], dim=1)\n",
    "        d2 = self.conv3(d2)\n",
    "        d1 = self.up4(d2)\n",
    "        s1_att = self.att4(g=d1, x=s1)\n",
    "        d1 = torch.cat([d1, s1_att], dim=1)\n",
    "        d1 = self.conv4(d1)\n",
    "        return self.outc(d1)\n",
    "\n",
    "# --- LOSS & METRICS ---\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs_sigmoid = torch.sigmoid(inputs)\n",
    "        bce = F.binary_cross_entropy_with_logits(inputs, targets, reduction='mean')\n",
    "        inputs_flat = inputs_sigmoid.view(-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "        intersection = (inputs_flat * targets_flat).sum()\n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs_flat.sum() + targets_flat.sum() + smooth)\n",
    "        return bce + dice_loss\n",
    "\n",
    "def keep_largest_component(mask):\n",
    "    \"\"\"Post-processing: Keep only the largest connected component.\"\"\"\n",
    "    labels = measure.label(mask)\n",
    "    if labels.max() == 0:\n",
    "        return mask\n",
    "    largest_cc = labels == np.argmax(np.bincount(labels.flat)[1:]) + 1\n",
    "    return largest_cc.astype(np.float32)\n",
    "\n",
    "# --- TRAINING ENGINE ---\n",
    "def train_fold(train_loader, val_loader, fold):\n",
    "    print(f\"\\n--- Training Fold {fold} ---\")\n",
    "    model = AttentionUNet().to(CONFIG[\"device\"])\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=1e-5)\n",
    "    criterion = DiceBCELoss()\n",
    "    \n",
    "    best_dice = 0.0\n",
    "    patience = 0\n",
    "    save_path = Path(CONFIG[\"save_dir\"]) / f\"best_model_fold_{fold}.pth\"\n",
    "    \n",
    "    for epoch in range(CONFIG[\"epochs\"]):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for img, msk in train_loader:\n",
    "            img, msk = img.to(CONFIG[\"device\"]), msk.to(CONFIG[\"device\"])\n",
    "            optimizer.zero_grad()\n",
    "            out = model(img)\n",
    "            loss = criterion(out, msk)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # Validate (Slice-wise Dice for monitoring)\n",
    "        model.eval()\n",
    "        val_dice = 0\n",
    "        with torch.no_grad():\n",
    "            for img, msk in val_loader:\n",
    "                img, msk = img.to(CONFIG[\"device\"]), msk.to(CONFIG[\"device\"])\n",
    "                out = model(img)\n",
    "                pred = (torch.sigmoid(out) > 0.5).float()\n",
    "                inter = (pred * msk).sum()\n",
    "                d = (2. * inter) / (pred.sum() + msk.sum() + 1e-8)\n",
    "                val_dice += d.item()\n",
    "        \n",
    "        val_dice /= len(val_loader)\n",
    "        \n",
    "        # Reporting\n",
    "        if (epoch+1) % 10 == 0 or DEBUG:\n",
    "            print(f\"  Ep {epoch+1}/{CONFIG['epochs']} | Loss: {train_loss/len(train_loader):.4f} | Val Dice: {val_dice:.4f}\")\n",
    "            \n",
    "        # Early Stopping\n",
    "        if val_dice > best_dice:\n",
    "            best_dice = val_dice\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        if patience >= CONFIG[\"early_stopping_patience\"]:\n",
    "            print(f\"  Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "            \n",
    "    # Ensure a file exists even if training fails or is skipped in debug\n",
    "    if not save_path.exists():\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        \n",
    "    return save_path\n",
    "\n",
    "def optimize_and_test(model_path, val_ds, test_ds):\n",
    "    \"\"\"\n",
    "    1. Find best params (threshold + post-proc) on VAL set (3D Patient Dice)\n",
    "    2. Apply those params to TEST set (3D Patient Dice)\n",
    "    \"\"\"\n",
    "    model = AttentionUNet().to(CONFIG[\"device\"])\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    # --- Helper to calculate 3D Dice for a dataset ---\n",
    "    def get_3d_dice(dataset, thresh, do_pp):\n",
    "        patient_data = {}\n",
    "        for s in dataset.samples:\n",
    "            if s['pid'] not in patient_data: patient_data[s['pid']] = []\n",
    "            patient_data[s['pid']].append(s)\n",
    "            \n",
    "        scores = []\n",
    "        with torch.no_grad():\n",
    "            for pid, samples in patient_data.items():\n",
    "                vol_pred, vol_gt = [], []\n",
    "                for s in samples:\n",
    "                    # Load original data\n",
    "                    img_vol = nib.load(s['img_path']).get_fdata()\n",
    "                    msk_vol = nib.load(s['msk_path']).get_fdata()\n",
    "                    z = s['slice_idx']\n",
    "                    img = img_vol[:,:,z]\n",
    "                    msk = msk_vol[:,:,z]\n",
    "                    \n",
    "                    # Preprocess\n",
    "                    p1, p99 = np.percentile(img, 1), np.percentile(img, 99)\n",
    "                    img = np.clip(img, p1, p99)\n",
    "                    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "                    \n",
    "                    # Tensorize\n",
    "                    img_t = torch.from_numpy(img.T).float().unsqueeze(0).unsqueeze(0).to(CONFIG[\"device\"])\n",
    "                    img_t = TF.resize(img_t, [CONFIG[\"image_size\"], CONFIG[\"image_size\"]], interpolation=T.InterpolationMode.BILINEAR, antialias=True)\n",
    "                    \n",
    "                    # Predict\n",
    "                    logits = model(img_t)\n",
    "                    pred = (torch.sigmoid(logits) > thresh).float().cpu().numpy().squeeze()\n",
    "                    \n",
    "                    if do_pp:\n",
    "                        pred = keep_largest_component(pred)\n",
    "                    \n",
    "                    # GT (Resize to match model output 256x256)\n",
    "                    msk_t = torch.from_numpy(msk.T).float().unsqueeze(0).unsqueeze(0)\n",
    "                    msk_t = TF.resize(msk_t, [CONFIG[\"image_size\"], CONFIG[\"image_size\"]], interpolation=T.InterpolationMode.NEAREST, antialias=True)\n",
    "                    gt = msk_t.numpy().squeeze()\n",
    "                    gt = (gt > 0).astype(np.float32)\n",
    "                    \n",
    "                    vol_pred.append(pred)\n",
    "                    vol_gt.append(gt)\n",
    "                \n",
    "                # Calculate 3D Dice for this patient\n",
    "                vp, vg = np.array(vol_pred), np.array(vol_gt)\n",
    "                dice = (2. * np.sum(vp * vg)) / (np.sum(vp) + np.sum(vg) + 1e-8)\n",
    "                scores.append(dice)\n",
    "        return np.mean(scores), np.std(scores)\n",
    "\n",
    "    # --- 1. Optimize on Validation ---\n",
    "    print(\"  Optimizing parameters on Validation Set...\")\n",
    "    best_val_score = -1\n",
    "    best_params = {'thresh': 0.5, 'pp': False}\n",
    "    \n",
    "    # Grid search\n",
    "    thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "    pp_options = [False, True]\n",
    "    \n",
    "    for th in thresholds:\n",
    "        for pp in pp_options:\n",
    "            score, _ = get_3d_dice(val_ds, th, pp)\n",
    "            if score > best_val_score:\n",
    "                best_val_score = score\n",
    "                best_params = {'thresh': th, 'pp': pp}\n",
    "    \n",
    "    print(f\"  Best Params found: Thresh={best_params['thresh']}, KeepLargest={best_params['pp']} (Val Dice: {best_val_score:.4f})\")\n",
    "    \n",
    "    # --- 2. Evaluate on Test ---\n",
    "    print(\"  Evaluating on Test Set with best params...\")\n",
    "    test_mean, test_std = get_3d_dice(test_ds, best_params['thresh'], best_params['pp'])\n",
    "    \n",
    "    return test_mean, test_std, best_params\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "full_df = pd.read_csv(CONFIG[\"manifest_path\"])\n",
    "final_results = []\n",
    "\n",
    "for fold in range(5):\n",
    "    # Garbage collection to be safe\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Split\n",
    "    test_fold = fold\n",
    "    val_fold = (fold + 1) % 5\n",
    "    train_folds = [f for f in range(5) if f != test_fold and f != val_fold]\n",
    "    \n",
    "    print(f\"\\n================ FOLD {fold} ================\")\n",
    "    print(f\"Train: {train_folds}, Val: {val_fold}, Test: {test_fold}\")\n",
    "    \n",
    "    # Datasets\n",
    "    df_train = full_df[full_df['fold'].isin(train_folds)]\n",
    "    df_val = full_df[full_df['fold'] == val_fold]\n",
    "    df_test = full_df[full_df['fold'] == test_fold]\n",
    "    \n",
    "    train_ds = OvaryDataset(CONFIG[\"data_root\"], df_train, augment=True, debug=DEBUG)\n",
    "    val_ds = OvaryDataset(CONFIG[\"data_root\"], df_val, augment=False, debug=DEBUG)\n",
    "    test_ds = OvaryDataset(CONFIG[\"data_root\"], df_test, augment=False, debug=DEBUG)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=CONFIG[\"num_workers\"])\n",
    "    val_loader = DataLoader(val_ds, batch_size=CONFIG[\"batch_size\"], shuffle=False, num_workers=CONFIG[\"num_workers\"])\n",
    "    \n",
    "    # Train\n",
    "    model_path = train_fold(train_loader, val_loader, fold)\n",
    "    \n",
    "    # Optimize & Test\n",
    "    mean_dice, std_dice, params = optimize_and_test(model_path, val_ds, test_ds)\n",
    "    \n",
    "    print(f\"RESULT FOLD {fold}: Test Dice = {mean_dice:.4f} ± {std_dice:.4f}\")\n",
    "    \n",
    "    # Save incrementally\n",
    "    final_results.append({\n",
    "        'fold': fold,\n",
    "        'test_dice': mean_dice,\n",
    "        'test_std': std_dice,\n",
    "        'best_thresh': params['thresh'],\n",
    "        'use_pp': params['pp']\n",
    "    })\n",
    "    \n",
    "    # Save CSV after every fold\n",
    "    pd.DataFrame(final_results).to_csv(Path(CONFIG[\"save_dir\"]) / \"final_results.csv\", index=False)\n",
    "\n",
    "print(\"\\n\\n=== DONE ===\")\n",
    "print(pd.DataFrame(final_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvr-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
